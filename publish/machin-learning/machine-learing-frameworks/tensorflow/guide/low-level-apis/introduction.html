<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="zh-CN" xml:lang="zh-CN">
<head>
<title>Introduction to TensorFlow's Low-Level-APIs</title>
<!-- 2018-10-10 Wed 10:50 -->
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="generator" content="Org-mode" />
<meta  name="author" content="stupid-coder" />
<link rel="stylesheet" title="Standard" href="/assets/worg.css" type="text/css" />
           <link rel="alternate stylesheet" title="Zenburn" href="/assets/worg-zenburn.css" type="text/css" />
           <link rel="alternate stylesheet" title="Classic" href="/assets/worg-classic.css" type="text/css" />
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2013 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<h1 class="title">Introduction to TensorFlow's Low-Level-APIs</h1>
<div id="table-of-contents">
<h2>&#30446;&#24405;</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">Tensor Values</a></li>
<li><a href="#sec-2">TensorFlow Core Walkthrough</a>
<ul>
<li><a href="#sec-2-1">Graph</a></li>
<li><a href="#sec-2-2">TensorBoard</a></li>
<li><a href="#sec-2-3">Session</a></li>
<li><a href="#sec-2-4">Feeding</a></li>
</ul>
</li>
<li><a href="#sec-3">Datasets</a></li>
<li><a href="#sec-4">Layers</a>
<ul>
<li><a href="#sec-4-1">Creating Layers</a></li>
<li><a href="#sec-4-2">Initializing Layers</a></li>
<li><a href="#sec-4-3">Executing Layers</a></li>
<li><a href="#sec-4-4">Layer Function shortcuts</a></li>
</ul>
</li>
<li><a href="#sec-5">Feature columns</a></li>
<li><a href="#sec-6">Training</a>
<ul>
<li><a href="#sec-6-1">Define the data</a></li>
<li><a href="#sec-6-2">Define the model</a></li>
<li><a href="#sec-6-3">Loss</a></li>
<li><a href="#sec-6-4">Training</a></li>
</ul>
</li>
</ul>
</div>
</div>
<p>
原文: <a href="https://www.tensorflow.org/guide/low_level_intro">https://www.tensorflow.org/guide/low_level_intro</a>
</p>

<p>
本文用来说明如何利用 TensorFlow 核心接口开发模型:
</p>
<ul class="org-ul">
<li>需要自己接管整个模型的开发和运行,使用 <b>tf.Graph</b> 来管理计算图, <b>tf.Session</b> 来
运行计算图.
</li>
<li>在核心接口中使用高阶组件(<b>datasets,layers 和 feature_columns</b>)
</li>
<li>不依赖 Estimator,采用核心接口构建训练流程.
</li>
</ul>


<p>
推荐采用高级别接口来构建模型,但是了解核心接口如何构建模型的话,可以从多个方面更好
的理解 TensorFlow:
</p>
<ul class="org-ul">
<li>在核心接口上进行实验和调试更为直观和灵活
</li>
<li>可以很好的理解高级别接口是如何工作的
</li>
</ul>

<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1">Tensor Values</h2>
<div class="outline-text-2" id="text-1">
<p>
TensorFlow 中核心数据类型为张量(<i>tensor</i>).张量就是多维矩阵, <b>rank</b> 为矩阵的维
度数量,形状标示了多维矩阵在维度上的大小:
</p>
<div class="org-src-container">

<pre class="src src-python">3. <span style="font-weight: bold; font-style: italic;"># </span><span style="font-weight: bold; font-style: italic;">a rank 0 tensor; a scalar with shape [],</span>
[1., 2., 3.] <span style="font-weight: bold; font-style: italic;"># </span><span style="font-weight: bold; font-style: italic;">a rank 1 tensor; a vector with shape [3]</span>
[[1., 2., 3.], [4., 5., 6.]] <span style="font-weight: bold; font-style: italic;"># </span><span style="font-weight: bold; font-style: italic;">a rank 2 tensor; a matrix with shape [2, 3]</span>
[[[1., 2., 3.]], [[7., 8., 9.]]] <span style="font-weight: bold; font-style: italic;"># </span><span style="font-weight: bold; font-style: italic;">a rank 3 tensor with shape [2, 1, 3]</span>
</pre>
</div>

<p>
TensorFlow 采用 NumPy 数组来表示内部张量的实际值.
</p>
</div>
</div>

<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2">TensorFlow Core Walkthrough</h2>
<div class="outline-text-2" id="text-2">
<p>
可以认为 TensorFlow 核心接口编程由两部分组成:
</p>
<ul class="org-ul">
<li>构建计算图(<b>tf.Graph</b>)
</li>
<li>运行计算图(<b>tf.Session</b>)
</li>
</ul>
</div>

<div id="outline-container-sec-2-1" class="outline-3">
<h3 id="sec-2-1">Graph</h3>
<div class="outline-text-3" id="text-2-1">
<p>
计算图(<i>computational graph</i>)是由多个 TensorFlow 操作符排列构成的,主要为两种
类型的对象组成:
</p>
<dl class="org-dl">
<dt> <code>tf.Operation</code> </dt><dd>计算图中的节点,Operation 描述了输入 Tensors 和产出 Tensors 的
计算过程.
</dd>
<dt> <code>tf.Tensor</code> </dt><dd>图中的边.表示了在图中流动的数据对象.绝大多数的 TensorFlow 方法
返回 <b>tf.Tensors</b>
</dd>
</dl>


<blockquote>
<p>
需要记住的是 tf.Tensors 并不是真正的包含数据,而是代表了计算图中的数据对象.
</p>
</blockquote>

<p>
构建一个简单的计算图.最基础的的操作符为常量.通过调用重载的加法函数接受两个
tensor,输入一个 tensor:
</p>
<div class="org-src-container">

<pre class="src src-python"><span style="font-weight: bold; font-style: italic;">a</span> = tf.constant(3.0, dtype=tf.float32)
<span style="font-weight: bold; font-style: italic;">b</span> = tf.constant(4.0) <span style="font-weight: bold; font-style: italic;"># </span><span style="font-weight: bold; font-style: italic;">also tf.float32 implicitly</span>
<span style="font-weight: bold; font-style: italic;">total</span> = a + b
<span style="color: #00bfff; font-weight: bold;">print</span>(a)
<span style="color: #00bfff; font-weight: bold;">print</span>(b)
<span style="color: #00bfff; font-weight: bold;">print</span>(total)
</pre>
</div>

<p>
上述代码输出:
</p>
<div class="org-src-container">

<pre class="src src-python">Tensor(<span style="color: #daa520; font-style: italic;">"Const:0"</span>, shape=(), dtype=float32)
Tensor(<span style="color: #daa520; font-style: italic;">"Const_1:0"</span>, shape=(), dtype=float32)
Tensor(<span style="color: #daa520; font-style: italic;">"add:0"</span>, shape=(), dtype=float32)
</pre>
</div>

<p>
上述打印张量,并没有输出希望的值 3.0, 4.0 和 7.0.上述的代码只是构建了计算图,这些
<b>tf.Tensor</b> 对象只是代表了计算图中的操作符执行的结果.
</p>

<p>
每一个计算图中的操作符都具有一个唯一的名字.这个名字和 python 中的变量名无关.张
量采用操作符和输出的索引来命名, (add:0) 如上.
</p>
</div>
</div>

<div id="outline-container-sec-2-2" class="outline-3">
<h3 id="sec-2-2">TensorBoard</h3>
<div class="outline-text-3" id="text-2-2">
<p>
TensorFlow 提供了工具 <b>TensorBoard</b>,该工具主要的一个功能是可视化计算图.
</p>

<p>
首先需要调用如下命令来保存计算图到 <b>TensorBoard</b> 文件中:
</p>
<div class="org-src-container">

<pre class="src src-python"><span style="font-weight: bold; font-style: italic;">writer</span> = tf.summary.FileWriter(<span style="color: #daa520; font-style: italic;">'.'</span>)
writer.add_graph(tf.get_default_graph())
</pre>
</div>

<p>
如上代码会在当前目录下生成一个 <b>event</b> 文件,命名规则如下:
</p>
<div class="org-src-container">

<pre class="src src-sh">instance_events.out.tfevents.{timestamp}.{hostname}
</pre>
</div>

<p>
然后在终端中调用 TensorBoard:
</p>
<div class="org-src-container">

<pre class="src src-sh">tensorboard --logdir .
</pre>
</div>

<p>
即可查看对应的可视化结果.
</p>
</div>
</div>

<div id="outline-container-sec-2-3" class="outline-3">
<h3 id="sec-2-3">Session</h3>
<div class="outline-text-3" id="text-2-3">
<p>
通过实例化 <b>tf.Session</b> 对象,该对象主要功能可以存储 TensorFlow 运行过程中的状态,并
且用来执行计算图. <b>tf.Graph</b> 类似 .py 文件, <b>tf.Session</b> 类似 python 解释器.
</p>

<p>
如下代码创建 <b>tf.Session</b> 对象,然后调用对应的 <b>run</b> 方法执行 total 张量,从而执
行实际的计算:
</p>
<div class="org-src-container">

<pre class="src src-python"><span style="font-weight: bold; font-style: italic;">sess</span> = tf.Session()
<span style="color: #00bfff; font-weight: bold;">print</span>(sess.run(total))
</pre>
</div>

<p>
<b>Session.run</b> 会根据需要计算的节点,从图上回溯需要计算的所有节点,然后送入对应
的参数,执行需要的计算,最终返回计算结果.所以上述代码会返回对应的希望结果 7.0:
</p>
<div class="org-src-container">

<pre class="src src-javascript">7.0
</pre>
</div>

<p>
<b>tf.Session.run</b> 可以接受多个张量作为参数.并且支持元素和字典:
</p>
<div class="org-src-container">

<pre class="src src-python"><span style="color: #00bfff; font-weight: bold;">print</span>(sess.run({<span style="color: #daa520; font-style: italic;">'ab'</span>:(a, b), <span style="color: #daa520; font-style: italic;">'total'</span>:total}))
</pre>
</div>

<p>
上述代码输出和输入结构一样:
</p>
<div class="org-src-container">

<pre class="src src-javascript">{<span style="color: #daa520; font-style: italic;">'total'</span>: 7.0, <span style="color: #daa520; font-style: italic;">'ab'</span>: (3.0, 4.0)}
</pre>
</div>

<p>
在每次 <b>tf.Session.run</b> 调用过程中,计算图中的任意 <b>tf.Tensor</b> 都能只有一个唯
一的值.例如:如下代码调用 <b>tf.random_uniform</b> 返回随机的 <b>tf.Tensor</b> :
</p>
<div class="org-src-container">

<pre class="src src-python"><span style="font-weight: bold; font-style: italic;">vec</span> = tf.random_uniform(shape=(3,))
<span style="font-weight: bold; font-style: italic;">out1</span> = vec + 1
<span style="font-weight: bold; font-style: italic;">out2</span> = vec + 2
<span style="color: #00bfff; font-weight: bold;">print</span>(sess.run(vec))
<span style="color: #00bfff; font-weight: bold;">print</span>(sess.run(vec))
<span style="color: #00bfff; font-weight: bold;">print</span>(sess.run((out1, out2)))
</pre>
</div>

<p>
结果显示每次调用 run 方法,结果都是不同的,但是在同一次 run 方法调用中随机值是固
定的(<b>out1</b> 和 <b>out2</b> 接受同一个输入):
</p>
<div class="org-src-container">

<pre class="src src-javascript">[ 0.52917576  0.64076328  0.68353939]
[ 0.66192627  0.89126778  0.06254101]
(
    array([ 1.88408756,  1.87149239,  1.84057522], dtype=float32),
    array([ 2.88408756,  2.87149239,  2.84057522], dtype=float32)
)
</pre>
</div>

<p>
有一些 TensorFlow 函数返回的是 <b>tf.Operations</b>.run 方法以 operation 作为参数调用
的时候,返回结果为 None,但是会执行相关的副作用.例如: <a href="#sec-4-2">Initializing Layers</a>和
<a href="#sec-6">Training</a>相关操作符.
</p>
</div>
</div>

<div id="outline-container-sec-2-4" class="outline-3">
<h3 id="sec-2-4">Feeding</h3>
<div class="outline-text-3" id="text-2-4">
<p>
计算图也可以接受参数作为输入,从而实现计算图的参数特化,该参数叫做占位符
(<i>placeholders</i>).占位符只是在计算图中占领一个节点,并且保证在后续实际计算图运
算时提供一个值作为输入.
</p>
<div class="org-src-container">

<pre class="src src-python"><span style="font-weight: bold; font-style: italic;">x</span> = tf.placeholder(tf.float32)
<span style="font-weight: bold; font-style: italic;">y</span> = tf.placeholder(tf.float32)
<span style="font-weight: bold; font-style: italic;">z</span> = x + y
</pre>
</div>

<p>
上述三行代码类似一个函数,定义了两个输入参数(<i>x,y</i>),然后执行一个操作.可以通过
在调用 <b>tf.Session.run</b> 方法时,将实际的值喂给对应的 <b>feed_dict</b> 参数,实现将值
喂给计算图中进行实际计算:
</p>
<div class="org-src-container">

<pre class="src src-python"><span style="color: #00bfff; font-weight: bold;">print</span>(sess.run(z, feed_dict={x: 3, y: 4.5}))
<span style="color: #00bfff; font-weight: bold;">print</span>(sess.run(z, feed_dict={x: [1, 3], y: [2, 4]}))
</pre>
</div>

<p>
结果如下:
</p>
<div class="org-src-container">

<pre class="src src-javascript">7.5
[ 3.  7.]
</pre>
</div>

<p>
feed_dict 参数可以用来覆盖计算图中任意的 tensor 值.placehodler 和 tensor 不同的地方
在于,在执行计算图的时候,placeholder 对象必须赋予实际的值,非则会抛出对应的异常
错误.
</p>
</div>
</div>
</div>

<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3">Datasets</h2>
<div class="outline-text-2" id="text-3">
<p>
占位符只适合执行小规模实验, <b>tf.data</b> 可以支持流式数据输入.
</p>

<p>
为了从 Dataset 中获取可以运行的 <b>tf.Tensor</b>,首先需要从 Dataset 中获取对应的迭代器
<b>tf.data.Iterator</b>,然后调用迭代器的 <b>tf.data.Iterator.get_next</b> 方法来获得对应
的数据.
</p>

<p>
最简单创建迭代器的方法是调用 <b>tf.data.Dataset.make_one_shot_iterator</b> 方法.如
下代码中, <b>next_item</b> 张量每次运行会从 my_data 数组中返回一行数据:
</p>
<div class="org-src-container">

<pre class="src src-python"><span style="font-weight: bold; font-style: italic;">my_data</span> = [
    [0, 1,],
    [2, 3,],
    [4, 5,],
    [6, 7,],
]
<span style="font-weight: bold; font-style: italic;">slices</span> = tf.data.Dataset.from_tensor_slices(my_data)
<span style="font-weight: bold; font-style: italic;">next_item</span> = slices.make_one_shot_iterator().get_next()
</pre>
</div>

<p>
Dataset 会在数据读取完成后,抛出 <b>tf.errors.OutOfRangeError</b> 错误.例如:如下代码
会一直读取 next_item,直到数据集没有数据:
</p>
<div class="org-src-container">

<pre class="src src-python"><span style="color: #00bfff; font-weight: bold;">while</span> <span style="font-weight: bold; text-decoration: underline;">True</span>:
  <span style="color: #00bfff; font-weight: bold;">try</span>:
    <span style="color: #00bfff; font-weight: bold;">print</span>(sess.run(next_item))
  <span style="color: #00bfff; font-weight: bold;">except</span> tf.errors.OutOfRangeError:
    <span style="color: #00bfff; font-weight: bold;">break</span>
</pre>
</div>

<p>
更为详细的数据集细节可以参考<a href="https://www.tensorflow.org/guide/datasets">importing data</a>.
</p>
</div>
</div>

<div id="outline-container-sec-4" class="outline-2">
<h2 id="sec-4">Layers</h2>
<div class="outline-text-2" id="text-4">
<p>
可训练的模型主要是通过微调计算图中的某些权值变量,从而实现相同的输入,执行计算图
中计算后能够获得不同的输出. <b>tf.layers</b> 是优先采用的方法,将可训练参数加到计算
图中.
</p>

<p>
网络层将可训练变量和对应执行的计算封装在一起.例如: <b>densely-connected layer</b>
用来执行输入值和权值点乘,然后执行激活函数.可训练的权值和偏置由网络层负责添加到
计算图中.
</p>
</div>

<div id="outline-container-sec-4-1" class="outline-3">
<h3 id="sec-4-1">Creating Layers</h3>
<div class="outline-text-3" id="text-4-1">
<p>
如下代码用来创建 <b>tf.layers.Dense</b> 网络层,接受 3 维的向量,然后生成一个单一节点:
</p>
<div class="org-src-container">

<pre class="src src-python"><span style="font-weight: bold; font-style: italic;">x</span> = tf.placeholder(tf.float32, shape=[<span style="font-weight: bold; text-decoration: underline;">None</span>, 3])
<span style="font-weight: bold; font-style: italic;">linear_model</span> = tf.layers.Dense(units=1)
<span style="font-weight: bold; font-style: italic;">y</span> = linear_model(x)
</pre>
</div>

<p>
网络层通过输入来决定内部的权重值维度.所以这里需要设置输入的占位符 x 的形状,从而
使得网络层可以构建内部权值矩阵.
</p>

<p>
上述定义了如何计算输入张量 <b>y</b> ,在执行计算前,还需要初始化网络层.
</p>
</div>
</div>

<div id="outline-container-sec-4-2" class="outline-3">
<h3 id="sec-4-2">Initializing Layers</h3>
<div class="outline-text-3" id="text-4-2">
<p>
网络层中包含一些变量,需要初始化后才能使用.TensorFlow 可以单个变量初始化,也可以
直接初始化整个计算图:
</p>
<div class="org-src-container">

<pre class="src src-python"><span style="font-weight: bold; font-style: italic;">init</span> = tf.global_variables_initializer()
sess.run(init)
</pre>
</div>

<p>
由于 <b>global_variables_initializer</b> 返回初始化操作符,该操作符只包含了调用时计
算图中需要初始化的变量.所以初始化操作应该是最后添加到计算图中的操作符.
</p>
</div>
</div>

<div id="outline-container-sec-4-3" class="outline-3">
<h3 id="sec-4-3">Executing Layers</h3>
<div class="outline-text-3" id="text-4-3">
<p>
网络层初始化后,就可以运行 <b>linear_model</b> 输出的张量:
</p>
<div class="org-src-container">

<pre class="src src-python"><span style="color: #00bfff; font-weight: bold;">print</span>(sess.run(y, {x: [[1, 2, 3],[4, 5, 6]]}))
</pre>
</div>
</div>
</div>

<div id="outline-container-sec-4-4" class="outline-3">
<h3 id="sec-4-4">Layer Function shortcuts</h3>
<div class="outline-text-3" id="text-4-4">
<p>
对于任意的网络层类(例如: tf.layers.Dense) TensorFlow 同时提供了一个快捷函数用来
快速构建对应的网络图(<b>tf.layers.dense</b>).快捷函数将网络层的创建和添加到计算图中集
中在一行代码中.例如:
</p>
<div class="org-src-container">

<pre class="src src-python"><span style="font-weight: bold; font-style: italic;">x</span> = tf.placeholder(tf.float32, shape=[<span style="font-weight: bold; text-decoration: underline;">None</span>, 3])
<span style="font-weight: bold; font-style: italic;">y</span> = tf.layers.dense(x, units=1)  <span style="font-weight: bold; font-style: italic;"># </span><span style="font-weight: bold; font-style: italic;">&#32593;&#32476;&#23618;&#21019;&#24314;&#21644;&#28155;&#21152;&#21040;&#35745;&#31639;&#22270;&#20013;</span>

<span style="font-weight: bold; font-style: italic;">init</span> = tf.global_variables_initializer()
sess.run(init)

<span style="color: #00bfff; font-weight: bold;">print</span>(sess.run(y, {x: [[1, 2, 3], [4, 5, 6]]}))
</pre>
</div>

<p>
快捷函数虽然可以将两部分操作合并在一个函数中.但是无法使得网络层重复使用,且不利于
调试.
</p>
</div>
</div>
</div>

<div id="outline-container-sec-5" class="outline-2">
<h2 id="sec-5">Feature columns</h2>
<div class="outline-text-2" id="text-5">
<p>
<b>feature columns</b> 为 TensorFlow 用来支持特征解析和变换的.最简单的使用就是通过定
义对应的 <b>feature columns</b> 解析对象后,通过调用 <b>tf.feature_column.input_layer</b>
方法来执行对应的特征解析和变换,该方法只接受 <b>dense columns</b> 作为输入,所以
<b>categorical column</b> 必须通过 <b>tf.feature_column.indicator_column</b> 转换成 <b>dense
column</b> 才能使用:
</p>
<div class="org-src-container">

<pre class="src src-python"><span style="font-weight: bold; font-style: italic;">features</span> = {
    <span style="color: #daa520; font-style: italic;">'sales'</span> : [[5], [10], [8], [9]],
    <span style="color: #daa520; font-style: italic;">'department'</span>: [<span style="color: #daa520; font-style: italic;">'sports'</span>, <span style="color: #daa520; font-style: italic;">'sports'</span>, <span style="color: #daa520; font-style: italic;">'gardening'</span>, <span style="color: #daa520; font-style: italic;">'gardening'</span>]}

<span style="font-weight: bold; font-style: italic;">department_column</span> = tf.feature_column.categorical_column_with_vocabulary_list(
        <span style="color: #daa520; font-style: italic;">'department'</span>, [<span style="color: #daa520; font-style: italic;">'sports'</span>, <span style="color: #daa520; font-style: italic;">'gardening'</span>])
<span style="font-weight: bold; font-style: italic;">department_column</span> = tf.feature_column.indicator_column(department_column)

<span style="font-weight: bold; font-style: italic;">columns</span> = [
    tf.feature_column.numeric_column(<span style="color: #daa520; font-style: italic;">'sales'</span>),
    department_column
]

<span style="font-weight: bold; font-style: italic;">inputs</span> = tf.feature_column.input_layer(features, columns)
</pre>
</div>

<p>
执行 inputs 张量,会解析 features 存储的批次特征值.
</p>

<p>
<b>feature columns</b> 内部包含状态,类似网络层,所以需要初始化后才能使用.categorical
columns 内部调用 <b>tf.contrib.lookup</b> 来查看对应的种类信息,所以需要额外的初始化操
作 <b>tf.tables_initializer</b>.
</p>
<div class="org-src-container">

<pre class="src src-python"><span style="font-weight: bold; font-style: italic;">var_init</span> = tf.global_variables_initializer()
<span style="font-weight: bold; font-style: italic;">table_init</span> = tf.tables_initializer()
<span style="font-weight: bold; font-style: italic;">sess</span> = tf.Session()
sess.run((var_init, table_init))
</pre>
</div>

<p>
初始化完成之后,就可以运行 inputs 张量来获取对应的结果值:
</p>
<div class="org-src-container">

<pre class="src src-python"><span style="color: #00bfff; font-weight: bold;">print</span>(sess.run(inputs))
</pre>
</div>
</div>
</div>

<div id="outline-container-sec-6" class="outline-2">
<h2 id="sec-6">Training</h2>
<div class="outline-text-2" id="text-6">
<p>
上述基本已经熟悉了 TensorFlow 核心接口基础知识,下面来手动训练一个简单的回归模型.
</p>
</div>

<div id="outline-container-sec-6-1" class="outline-3">
<h3 id="sec-6-1">Define the data</h3>
<div class="outline-text-3" id="text-6-1">
<p>
首先定义输入 x,和希望输出 y_true:
</p>
<div class="org-src-container">

<pre class="src src-python"><span style="font-weight: bold; font-style: italic;">x</span> = tf.constant([[1], [2], [3], [4]], dtype=tf.float32)
<span style="font-weight: bold; font-style: italic;">y_true</span> = tf.constant([[0], [-1], [-2], [-3]], dtype=tf.float32)
</pre>
</div>
</div>
</div>

<div id="outline-container-sec-6-2" class="outline-3">
<h3 id="sec-6-2">Define the model</h3>
<div class="outline-text-3" id="text-6-2">
<p>
接着构建一个简单的线性模型:
</p>
<div class="org-src-container">

<pre class="src src-python"><span style="font-weight: bold; font-style: italic;">linear_model</span> = tf.layers.Dense(units=1)

<span style="font-weight: bold; font-style: italic;">y_pred</span> = linear_model(x)
</pre>
</div>

<p>
然后就可以直接进行评估预测结果:
</p>
<div class="org-src-container">

<pre class="src src-python"><span style="font-weight: bold; font-style: italic;">sess</span> = tf.Session()
<span style="font-weight: bold; font-style: italic;">init</span> = tf.global_variables_initializer()
sess.run(init)

<span style="color: #00bfff; font-weight: bold;">print</span>(sess.run(y_pred))
</pre>
</div>

<p>
由于模型没有经过训练所以结预测的结果并不会太好.
</p>
</div>
</div>

<div id="outline-container-sec-6-3" class="outline-3">
<h3 id="sec-6-3">Loss</h3>
<div class="outline-text-3" id="text-6-3">
<p>
为了优化模型,首先需要定义损失函数.这里采用标准的回归模型采用的损失函数: <b>均值平方差</b>.
</p>

<p>
<b>tf.losses</b> 模块中提供了很多常用的损失函数,如下为对应的均值平方差错误:
</p>
<div class="org-src-container">

<pre class="src src-python"><span style="font-weight: bold; font-style: italic;">loss</span> = tf.losses.mean_squared_error(labels=y_true, predictions=y_pred)

<span style="color: #00bfff; font-weight: bold;">print</span>(sess.run(loss))
</pre>
</div>
</div>
</div>

<div id="outline-container-sec-6-4" class="outline-3">
<h3 id="sec-6-4">Training</h3>
<div class="outline-text-3" id="text-6-4">
<p>
TensorFlow 提供了很多优化算法,所有的优化算法都是 <b>tf.train.Optimizer</b> 的子类实现.通
过调整计算图中的可训练的权值来最小化损失函数.最简单的优化算法是梯度下降,具体实现
为 <b>tf.train.GradientDescentOptimizer</b>,通过求解参数的梯度值,然后朝反方向进行调整:
</p>
<div class="org-src-container">

<pre class="src src-python"><span style="font-weight: bold; font-style: italic;">optimizer</span> = tf.train.GradientDescentOptimizer(0.01)
<span style="font-weight: bold; font-style: italic;">train</span> = optimizer.minimize(loss)
</pre>
</div>

<p>
上述代码将优化算法需要执行的所有计算操作符都添加到计算图中,并返回对应的训练操作
符.当执行该操作符的时候,计算会根据优化算法更新计算图中的可训练变量.
</p>
<div class="org-src-container">

<pre class="src src-python"><span style="color: #00bfff; font-weight: bold;">for</span> i <span style="color: #00bfff; font-weight: bold;">in</span> <span style="font-weight: bold;">range</span>(100):
    <span style="font-weight: bold; font-style: italic;">_</span>, <span style="font-weight: bold; font-style: italic;">loss_value</span> = sess.run((train, loss))
    <span style="color: #00bfff; font-weight: bold;">print</span>(loss_value)
</pre>
</div>

<p>
由于 <b>train</b> 是一个操作符,而非 tensor,所以返回结果为 None.
</p>
</div>
</div>
</div>
</div>
</body>
</html>
