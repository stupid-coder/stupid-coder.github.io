#+TITLE: Putting it together: Minimal Neural Network Case Study
#+AUTHOR: stupid-coder
#+EMAIL: stupid_coder@163
#+OPTIONS: H:2 num:nil
#+STARTUP: indent

[[http://cs231n.github.io/neural-networks-case-study/][cs231n-neural-networks-case-study]]

本文将实现一个完整的，具有教学意义的神经网络。首先实现一个简单的线性分类器，然后
在该分类器的基础上稍作改动就可以扩展成 2-层神经网络。

* Generating some data
首先生成一个分类数据集，该数据集不需要是线性可分的。一个比较适合的数据集是螺旋分
布：
#+BEGIN_SRC python
  N = 100 # number of points per class
  D = 2 # dimensionality
  K = 3 # number of classes
  X = np.zeros((N*K,D)) # data matrix (each row = single example)
  y = np.zeros(N*K, dtype='uint8') # class labels
  for j in xrange(K):
    ix = range(N*j,N*(j+1))
    r = np.linspace(0.0,1,N) # radius
    t = np.linspace(j*4,(j+1)*4,N) + np.random.randn(N)*0.2 # theta
    X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]
    y[ix] = j
    # lets visualize the data:
  plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)
  plt.show()
#+END_SRC
-----
#+BEGIN_CENTER
#+CAPTION: 螺旋数据集
[[file:assets/eg/spiral_raw.png]]
#+BEGIN_QUOTE
具有三种类别信息的螺旋数据集。
#+END_QUOTE
#+END_CENTER
-----
一般需要对输入的数据进行预处理，包括中心化，标准差，PCA 等。但是本样本集已经是分
布在[-1, +1]之间，且样本维度较小，所以无需处理。


* Training a Softmax Linear Classifier
** Initialize the parameters
首先训练一个 /Softmax classifier/ 线性得分函数，并使用交叉熵作为损失函数。线性分
类器由权值矩阵 /W/ 和 偏置向量 /b/ 组成。首先初始化参数：
#+BEGIN_SRC python
  # initialize parameters randomly
  W = 0.01 * np.random.randn(D,K)
  b = np.zeros((1,K))
#+END_SRC

** Compute the class scores
通过矩阵运算可以并行计算样本的所有类别的对应得分：
#+BEGIN_SRC python
  # compute class scores for a linear classifier
  scores = np.dot(X, W) + b
#+END_SRC

上述的样本集具有 300 个 2-D 样本，乘法运算后 /scores/ 数组为[300,3]维度，每一行
为单个样本所有对应的 3 个类别的对应得分(蓝色，红色，黄色)。

** Compute the loss


** Computing the analytic gradient with backpropagation
** Performing a parameter update
** Putting it all together: Training a Softmax Classifier
* Training a Neural Network

* Summary
