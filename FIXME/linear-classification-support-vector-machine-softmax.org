#+TITLE: Linear classification: Support Vector Machine, Softmax
#+ALT_TITLE: parameteric approach, bias trick, hinge loss, cross-entropy loss, L2 regularization, web demo
#+AUTHOR: stupid-coder
#+EMAIL: stupid_coder@163.com

* Linear Classification
  在上部分，介绍了图像分类的问题。根据输入的图像，分类器会给图像分配一个标签，该
  标签是在规定的类别(*categories*)中。 /kNN/ 通过比较输入图像和训练集中的图像的
  相似度，获取前k的图像标记进行投票。 /kNN/ 很明显具有如下缺点：
  + 分类器必须记录所有的训练集样本。在训练集较大时，需要消耗大量的内存进行存储
  + 预测时候，需要进行逐一比较，需要消耗大量的计算


  文本将去开发一个更为有效的方法进行图像分类，并且后续很容易扩展成神经网络
  (/Neural Networks/)和卷积神经网络(/Convolutional Neural Networks/)。该方法具有
  两个主要的模块： *score function* 将原始数据映射到类别得分； *loss function*
  用来度量预估的得分和实际真的标签的差距。这样，可以看作通过调整得分函数的参数最
  小化损失函数的优化问题。

* Parameterized mapping from images to label scores
  *score function* 用来将原图像数据射到每一个类别，并且得到对应的置信得分
   (/confidence scores/)。

   假设具有一个图像训练集，其中的图像 /x_{i} \in R^{D}/ ，都具有一个标签数据
   /y_{i}/ ， /i = 1 ... N/ 并且 /y_{i} \in 1 ... K/ 。也就是说总共具有 /N/ 样本
   (每个样本具有的数据维度是 /D/)和 /K/ 个类别。例如：在CIFAR-10中，总共有
   /N=50K/ 的训练图像数据，每一个图像具有 /D=32*32*3/ 的维度像素；并且 /K=10/ ，
   表示总共有10类(dog,cat,car,etc)。这里定义 *score function* /f: R^{D} ->
   R^{K}/ ，用于将原始图像像素映射到类别得分。

* Linear classifier
  本文先介绍一个最简单的得分函数，线性分类：

  \begin{equation}
  f(x_{i},W,b) = Wx_{i} + b
  \end{equation}
   
  在上述的等式中，假设输入图像 /x_{i}/ ，将3维图像数组压平成一维列数组 /形状 [D,1]/
  。矩阵 /W/ (形状 /[K, D]/)和向量 /b/ (形状 /[K, 1]/)为得分函数的参数空间。
  /W/ 一般称为权重值 /weights/ ， /b/ 一般成为偏置 /bias/ 。

  这里有一些事情需要关注：
  + 矩阵运算 /Wx_{i}/ 一次可以直接并行计算K个不同类别的分类器，每个分类器是权值
    矩阵 /W/ 的一行。
  + 基于输入的样本，主要是要控制参数 /W，b/ 使得最后的类别得分能够和真实的类别
    标签像匹配，并且真实的类别标签的得分高于其他标签的得分。
  + 这种学习的方法的优点在于，只需要去学习调整参数 /W，b/ ，最后只需要记住 /W，
    b/ 即可，而不需要记住全部的训练样本。
  + 预测阶段，只需要计算一次矩阵乘法运算和偏置加法运算，要比遍历训练数据集的
    *kNN*算法要快很多

* Interpreting a linear classifier
  *linear classifier* 就是将每个通道的像素值进行权值加和。权值影响着每一个位置的
  和通道的像素对类别的关联程度(正值是正相关、负值是负相关、零代表无关)。例如：类
  别为 *船* 的图像背景像素常常会是蓝色(/大海的颜色/)。这样在这些像素区域和蓝色通
  道上会有一个较大的权值，会增加分到类别 *船* 的分数变大。

  -----
  #+CAPTION: 图像线性分类器
  [[file:assets/imagemap.jpg]]
  -----

** Analogy of images as high-dimensional points
   每张图像会被拉伸成一维的高维向量，所以可以将这些图像看作是高维空间的一个坐标
   点(CIFAR-10中每张图像的维度为3072=32*32*3)。整个样本集可以看作是这些坐标点组
   成的。

   我们无法可视化这么高维度的空间，但是如果假设我们可以对这些高维压缩到只有2维，
   那么我们就可以可视化这个分类器到底是做什么？

   -----
   #+CAPTION: 可视化分类器
   [[file:assets/pixelspace.jpeg]]
   #+BEGIN_QUOTE
   每一个图片都是一个坐标点，其中可视化了3个分类器。红色的线是汽车的分类器，在该
   线上的坐标点代表都是获得类别是汽车得分为0的点。箭头代表分数的增加方向，所以所
   有在红色分类器右边的点都具有类别是汽车得分大于0的点，所有在红色分类器左边的点
   的类别是汽车的得分都是小于0的点。
   #+END_QUOTE
   -----

   在权值矩阵 /W/ 中的每一行都对应一个类别的分类器。并且控制着线性分类器的方向
   (梯度)。偏置 /b/ 代表着该类别的分类器在0点的分类点，如果所有的分类器的偏置为0，
   那么在 /x_i=0/ ，则所有的分类器都会交叉到原点。
   
** Interpretation of linear classifiers as template matching
   另外一种解释，可以将权值矩阵 /w/ 的每一行为对应列别的模板。类别的得分就是用内
   积来计算图像与模板的匹配程度。这样，分类器就是去学习不同类别的模板，然后分类
   器用这些模板去进行分类。

   -----
   #+CAPTION: 分类器模板匹配
   [[file:assets/templates.jpg]]
   #+BEGIN_QUOTE
   上图是在CIFAR-10上学习到的线性分类器权值矩阵在不同类别上的可视化结果。可以看
   到 *船* 类别的模板大多数都是蓝色，也就是说如果图像中的像素点很多都是蓝色的，
   那么 *船* 类别的得分会比较高
   #+END_QUOTE
   -----

   从上图，可以看到 /马/ 类别的模板上，有马头朝左和朝右，主要原因是数据集中包含
   了马头朝左的图像，也包含了马头朝右的图像。线性分类器将这两种马的图像模板合并
   到了一个模板中。 /汽车/ 类别的模板融合了各个朝向和个种颜色的模板，最后模板呈
   现红色，代表CIFAR-10中的汽车图像红色车较多。线性分类器描述能力太弱，不足以区
   分不同颜色的汽车图像。神经网络(/neural network/)可以通过隐含层的中间节点来检
   测任何类型的汽车图像(绿色车头向左，红色车头向前)，下一层的神经元可以将这些信
   息进行合并，并获取较高分数，从而能够分辨出各种各样的汽车图像。

** Bias trick
   现在我们有两个主要参数类型： /W/ 和 /b/ 。定义的得分函数：
   /begin{equation}
   f(x_{i},W,b) = Wx_{i} + b
   /end{equation}

   如果对 /x_{i}/ 进行扩展一列，并保持该列为1(/bias dimension/)，那么上述的公式
   可以改写为：
   /begin{equation}
   f(x_{i},W) = Wx_{i}
   /end{equation}

   -----
   #+CAPTION: 融合权值矩阵和偏置向量
   [[file:assets/wb.jpeg]]
   #+BEGIN_QUOTE
   通过对输入向量进行行扩展，并且保持该行的为常量1，那么就可以将权值矩阵和偏置向
   量融合成一个新的权值矩阵。
   #+END_QUOTE
   -----

** Image data preprocessing
   在机器学习中，有一个很重要的技巧就是对输入数据进行归一化。图像中，首先计算训
   练集中图像的像素均值，然后每个像素点减去该均值，使得图像的像素值在范围[-127,
   127]之间，然后归一化到[-1, 1]之间。后续在进行最优化求解的时候，可以看到归一化
   的好处。

* Loss function
  
** Multiclass SVM

** Softmax classifier

** SVM vs. Softmax

* Interactive Web Demo of Linear Classification
* Summary
