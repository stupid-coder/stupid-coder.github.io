#+TITLE: Very Deep Convolutaional Networks for Large-Scale Image Recognition
#+AUTHOR: stupid-coder
#+EMAIL: stupid_coder@163.com
#+OPTIONS: H:2 num:nil
#+STARTUP: indent


原文: [[https://arxiv.org/pdf/1409.1556.pdf][Very Deep Convolutional Networks for Large-Scale Image Recognition]]

#+BEGIN_QUOTE
本文研究了卷积神经网络深度在大规模图像识别任务准确性上的影响.本文主要的贡献是详细评估了只采用小卷积核(3*3)的网络结构通过增加网络深度到 16-19 层后,可以较大提升图像文类精度.这些发现是基于 ImageNet-2014 比赛提交的网络结构,该网络在目标定位和图像分类两个任务中分别获得了第一和第二.同时通过实验,可以看到该网络在其他的数据集上也具有泛化能力.
#+END_QUOTE

* Introduction
深度卷积网络在多个图像识别任务中都获得了非常大的成功.在卷积神经网络在机器视觉领域变的越来越常见,现在有很多论文都是在研究如何在 AlexNet 网络结构上通过变形来提高网络分类效果.例如:2013-ILSVRC 的最好模型(/ZFNet/)通过在第一层采用较小的感受野窗口和更小的步长获取了更好的分类效果.另外一个提高的方法是在训练和测试网络采用多尺度图像[fn:1][fn:2].本文通过固定网络结构的其它参数,通过使用非常小的卷积核(3*3),增加卷积网络的卷积层数,探讨卷积神经网络深度对模型效果的影响.

* ConvNet Configurations
为了度量卷积网络深度对模型精度带来的影响,本文中的卷积层参数都是一样的.

** Architecture
网络接受固定大小 224*224 的三通道图像作为输入.唯一做的预处理是减去训练集中的 RGB 三通道的均值.然后图像会经过一系列 3*3 大小的卷积层.在某个网络结构中也会采用 1*1 的卷积核,这个卷积可以看作是在输入通道上做线性变变换,然后跟着一个非线性变换.卷积操作的步长固定为 1 个像素;卷积层进行空间填充来保证输入特征图和卷积后的特征图空间维度保持一样,例如对于 3*3 卷积层填充 1 个像素.每个网络结构都具有 5 个感受野为 2*2,步长为 2 的最大采样层.

卷积层之后跟着三层全链接层:前两层具有 4096 个神经元,第三层为 1000 路的 softmax 分类层.所有的网络结构采用相同的全链接层结构.

所有的隐藏层激活函数都是采用 ReLU.并且本文除了一个网络,其他网络结构并不采用 AlexNet 提到的局部相应归一化(/Local Response Normalisation/),这种归一化操作并不会提高模型的效果,而且会带来更多的内存消耗和计算时间.

** Configurations
本文的网络结构如[[table-1][表 1]]所示,每一列都是一个模型结构.网络具有相似的结构,除了在深度上不同:从网络 A 的 11 层(8 层卷积层+3 层全链接层)到网络 E 的 19 层(16 层卷积层+3 层全链接层).卷积层的通道数比较小,从 64 开始,每个最大采样层增加 2 倍,直到 512.

#+BEGIN_CENTER
#+NAME: table-1
#+CAPTION: 卷积网络结构配置(一列为一个网络结构).网络结构由左(A)向右(E)加深,每列的深色层为新增加的网络层.卷积层的参数由 *conv<receptive field size>-<number of channels>* 定义.激活函数 ReLU 在配置没有显示.
[[file:assets/vgg-net/table-1.png]]
#+END_CENTER

[[table-2][表-2]]显示了不同网络配置下的参数数量.即使具有较大的网络深度,本文提出的模型参数数量也没有采用更深和更大的卷积层参数要少(144M[fn:2]).

#+NAME: table-2
#+CAPTION: 参数数量(M)
| Network  | A,A-LRN |   B |   C |   D |   E |
|----------+---------+-----+-----+-----+-----|
| 参数数量 |     133 | 133 | 134 | 138 | 144 |

** Discussion
本文的卷积神经网络结构和 AlexNet,ZFNet 都不一样.AlexNet 第一层为感受野为 11*11,步长为 4 的卷积层,ZFNet 第一层为感受野为 7*7,步长为 2 的卷积层.本文提出的网络只采用感受野 3*3,步长为 1 的卷积操作.两层 3*3 卷积层的感受野就是 5*5,三层 3*3 卷积层的感受野就是 7*7.那么,使用三层 3*3 卷积层级联来代替 7*7 卷积层会带来什么收益呢?首先,采用 3 个非线性变换层而非一个,使得分类函数具有更强的分类能力.其次,降低了参数规模:假设三层 3*3 卷积层的输入和输出深度为 C,那么参数规模为 $3(3^{2}C^{2})=27C^{2}$;同时,一个单独的 7*7 卷积层需要 $7^{2}C^{2}=49C^{2}$ 个参数,多出 81% 的参数.参数规模下降,可以看作是引入了正则化效果,强制 7*7 卷积核分解成多个 3*3 卷积核(卷积层之间具有非线性变换).

网络 C 引入了 1*1 卷积层来增加分类函数的非线性能力,并且不会影响卷积层的感受野.虽然本文引入的 1*1 卷积层通过线性映射到相同的深度维度,但是由于激活函数引入了非线性能力.1*1 卷积层在 Network in Network 中得到应用[fn:3].

Goodfellow et al.[fn:4]采用深度卷积网络(11 层)来识别街道门牌号,并显示了增加网络深度,可以获得更好的识别效果.GoogLeNet[fn:5]在 ILSVRC-2014 分类比赛中获得最好成绩,虽然和本文的工作独立,但是思想类似,采用非常深的卷积网络(22 层)和较小的卷积核(3*3,1*1,5*5).GoogLeNet 的网络结构要比本文的网络复杂的多,并且在第一层就更为激进的减小特征图尺度,从而减少计算量.并且在单个网络分类准确性上本文的网络要比 GoogLeNet 要好.

* Classification Framework
前一部分介绍了网络结构.本部分介绍了分类卷积网络的训练和评估细节.

** Traning
卷积网络的训练过程一般都和 AlexNet 相同(除了后面介绍的从多种尺度训练图像中裁剪采样流程).即,训练过程采用结合动能的小批量随机梯度下降优化算法,通过反向传播算法最小化多目标逻辑斯特回归(/multinomial logistic regression/).批量大小为 256,动能系数为 0.9.训练过程采取权值衰减来实现参数正则化($L_{2} 惩罚系数为 5*10^{-4}$),在全链接层前两层使用 dropout 正则化(dropout 系数为 0.5).学习率最开始设置为 10^{-2},然后在验证集准确性停止上升时,对学习率衰减 10 倍.最后,当学习率衰减 3 次后,训练经过 370K 迭代后停止(74 轮).推测由于和 AlexNet 比,采用了更大的参数空间和更深的网络结构,网络需要更少轮训练就可以收敛是因为:(a)更深网络和更小卷积核隐含带来的正则化;(b) 某些层的预初始化.

因为不好的权值初始化可以阻止深度网络学习,所以网络的权值初始化非常重要.为了避免这个问题,先训练较浅的网络 A,较浅的网络即使采用随机初始化权值也能很好的收敛.当训练较深的网络结构,采用网络 A 的权值来初始化最开始的四层卷积层和最后三层全链接层,新增加的层采用随机初始化.预初始化的网络层的学习率并不衰减,从而允许这些网络层在训练过程中迭代更新.随机初始化以 0 为均值,10^{-2}方差进行正态化采样.偏置初始化为 0.可以注意到通过采用 Glorot&Bengio[fn:6]提出的随机初始化方法,可以不用预训练权重就可以使得网络收敛.

从调整的训练数据中随机裁剪一个固定的 224*224 尺度图像(每轮每个图像进行随机裁剪).为了进一步增加训练集数据,可以对图像进行随机水平反转和随机 RGB 颜色偏移,具体可以参考 AlexNet.训练集图像的调整如下所述.

-----
*Training image size.* 设 S 为训练图像缩放后的最小边尺度.卷积网络输入图像从这个缩放图像中进行裁剪(S 为训练集尺度).裁剪尺度固定为 224*224,原理上,S 不能小于 224:当 S=224,直接使用整张图像作为输入;在 S>>224,裁剪图像的一小部分.

本文采用两个方法确定训练集的尺度 S.第一种是固定 S,这样裁剪后的图像仍然可以包含多尺度图像信息.在实验中,采用两种固定尺度来评估模型: S=256(AlexNet,ZFNet 和 OverFeat 中使用)和 S=384.对于一个网络结构,首先采用 S=256 训练网络.采用 S=256 尺度的预训练模型初始化网络来加速训练 S=384 的网络,并且采用更小的学习率 10^{-3}.

第二种方法采用多尺度 S,训练数据随机从范围 $[S_{min},S_{max}]$ 中选取图像缩放尺度(本文采用 $S_{min}=256$ 和 $S_{max}=512$).由于目标在图像中具有多种尺度,这种训练方法效果更好.这样可以看作在训练集上进行多尺度增强,从而使得单个模型可以识别多尺度的目标.为了加速训练,对于多尺度模型可以采用和单尺度 S=384 模型的网络结构,并且采用预训练的权值进行初始化.

** Testing
测试时,对于输入图像分类流程如下:

首先,将输入图像分辨率缩放到预定义的最小图像分辨率,记为 Q(叫做测试尺度).Q 并不需要和训练尺度 S 相同.然后采用和 OverFeat[fn:2]类似的方法在测试图像上进行多尺度检测.即,首先将全链接层转为对应的卷积层(第一层全链接层转为 7*7 卷积层,后两层全链接层转为 1*1 卷积层).这样将整个网络转为卷积网络,整张未裁剪的测试图像可以直接送到网络中,最后得到和图像分辨率有关的分类得分.最后,在空间上对分类得分向量进行加和平均得到最后图像的分类得分.并且对测试图像进行了水平反转来增强测试集,并将水平反转得到的分类得分向量和原始图像的分类的得分向量进行加和平均得到最后分类得分.

因为采用了全卷积网络,所以就不需要在测试阶段采用多次裁剪和采样计算分类得分,从而加速整个测试流程.同时,采用全部图像的裁剪子集来作测试,可以提高分类性能.

* Classification Experiments
*Dataset.* 数据集采用 ILSVRC-2012 数据集.数据集包含 1000 个类别,3 个数据集:训练集(1.3M),验证集(50K),测试集(100K).分类性能采用两个方式评估:top-1 和 top-5 错误率.

** Single Scale Evaluation
在每个卷积网络结构上评估单一尺度验证集.测试数据设置: 对于固定 S, 设置 Q=S;对于不定 $S \in [S_{min};S_{max}]$,设置 $Q=0.5(S_{min}+S_{max})$, 结果如[[table-3][表-3]]所示.

#+BEGIN_CENTER
#+NAME: table-3
#+CAPTION: 单一尺度测试集上的模型表现.
[[file:assets/vgg-net/table-3.png]]
#+END_CENTER

首先,我们可以看到,采用了局部响应值归一化操作(A-LRN 网络)并没有提高模型分类效果.所以没有在更深的网络结构中采用(B-E).

其次,可以看到分类错误率随着网络深度的加深而降低:从 A 网络的 11 层到 E 网络的 19 层.在相同深度,C 网络包含 3 个 1*1 卷积层的表现要比 D 网络全部采用 3*3 卷积要差.这说明额外的非线性变换确实具有一定的帮助(C 网络要比 B 网络好),但是同样重要的是具有较大感受野的卷积核能够捕捉更多的空间信息(D 网络要比 C 网络好).错误率在网络达到 19 层后停止下降,但是更深的网络可能在更大的数据集有更好的表现.并且,本文对比了将 B 网络结构的成对的 3*3 卷积核替换成一个 5*5 的卷积核(两个具有相同的感受野)后的 5 层较浅的卷积网络.top-1 错误率要比 B 网络高 7%,这也说明了具有较小卷积核的更深的网络要比具有较大卷积核浅网络表现要好.

最终,在训练阶段对训练数据进行多尺度缩放($S \in [256;512]$)会带来效果的提升.也就是说在训练阶段对数据进行多尺度增强会帮助模型获得更多多尺度图像信息.

** Multi-Scale Evaluation
上述评估在测试集采用单一尺度图像进行的,现在讨论一下在测试阶段采用多尺度图像评估的效果.具体过程包括采用多吃的测试图像(对应于不同的 Q 值),然后将分类结果向量进行平均.可以想象的就是训练集和测试集尺度变化太大一定会带来模型效果的变差,所以在评估以 S 尺度作为训练的模型时,评估采用 3 个图像尺度,这些尺度接近于训练集: $Q={S-32,S,S+32}$.同时,如果训练数据集尺度不定 $S \in [S_{min};S_{max}]$ ,那么评估集尺度 $Q={S_{min},0.5(S_{min}+S_{max}),S_{max}}$.

评估结果如[[table-4][表-4]]所示,显示在测试阶段采用多尺度图像评估,并对结果进行平均会带来更好的性能(相同的网络结构与单一测试尺度结果相比,如[[table-3][表-3]]所示).一样的,最深的网络(D 和 E)表现最好,并且采用多尺度数据集进行训练的模型要比单一尺度训练的模型要好.

#+BEGIN_CENTER
#+NAME: table-4
#+CAPTION: 多尺度训练集上的表现效果.
[[file:assets/vgg-net/table-4.png]]
#+END_CENTER

** Multi-Crop Evaluation
[[table-5][表-5]]显示了全评估和多次剪切评估.并且评估了将两种评估方法结合在一起的效果.可以看到,多次剪切的效果要比全评估要稍微好一些,并且两个方法可以互补,因为结果要比任何一个单独的方法要好.推测原因是结合了不同的卷积边界情况带来了一些信息互补.

#+BEGIN_CENTER
#+NAME: table-5
#+CAPTION: 多种评估技术对比.所有的实验中的训练尺度 S 从[256;512]采样,测试尺度 Q 为{256,384,512}.
[[file:assets/vgg-net/table-5.png]]
#+END_CENTER

** ConvNet Fusion
之前,都是在单个卷积网络模型上评估效果.本部分的实验,通过结合多个模型的输出,从而提高了模型的性能.

结果如[[table-6][表-6]]所示,将 7 个卷积网络集成在一起在 ILSVRC 测试集上的错误率为 7.3%.然后,将两个表现最好的模型(D 和 E)集成在一起,全评估错误率为 7.0%,组合使用全评估和剪切评估错误率为 6.8%.

#+BEGIN_CENTER
#+NAME: table-6
#+CAPTION: 多模型融合结果
[[file:assets/vgg-net/table-6.png]]
#+END_CENTER

** Comparison With The State Of The Art
最后在[[table-7][表-7]]评估了本文的模型和其他最好的模型的对比结果.在 ILSVRC-2014 分类竞赛中,本文提出的 VGG 网络融合使用 7 个网络模型达到了测试错误率 7.3%,获得了第二名.提交结果后,本文通过融合 2 个最好的模型,从而将错误率降到了 6.8%.

#+BEGIN_CENTER
#+NAME: table-7
#+CAPTION: ILSVRC 分类中模型比较.
[[file:assets/vgg-net/table-7.png]]
#+END_CENTER

可以看到单个网络模型中,本文的模型测试错误率可以达到 7.0%,要比单个网络模型 GoogLeNet 的 7.9% 要好.

* Footnotes

[fn:6] Glorot, X. and Bengio, Y. Understanding the difficulty of training deep feedforward neural networks. In Proc.AISTATS, volume 9, pp. 249–256, 2010.

[fn:5] Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V., and Rabinovich, A. Going deeper with convolutions. CoRR, abs/1409.4842, 2014.

[fn:4] Goodfellow, I. J., Bulatov, Y., Ibarz, J., Arnoud, S., and Shet, V. Multi-digit number recognition from street view imagery using deep convolutional neural networks. In Proc. ICLR, 2014.

[fn:3] Lin, M., Chen, Q., and Yan, S. Network in network. In Proc. ICLR, 2014.

[fn:2] Sermanet, P., Eigen, D., Zhang, X., Mathieu, M., Fergus, R., and LeCun, Y. OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks. In Proc. ICLR, 2014.

[fn:1] Howard, A. G. Some improvements on deep convolutional neural network based image classification. In Proc. ICLR, 2014.
